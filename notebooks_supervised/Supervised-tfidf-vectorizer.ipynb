{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb957c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a064f7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>uncommon</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>stem</th>\n",
       "      <th>discourse</th>\n",
       "      <th>cohesive_features</th>\n",
       "      <th>flesch</th>\n",
       "      <th>dale</th>\n",
       "      <th>mcalpine</th>\n",
       "      <th>nouns_adjs</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[there, is, manuscript, evidence, that, austen...</td>\n",
       "      <td>35</td>\n",
       "      <td>4.485714</td>\n",
       "      <td>1.371429</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>there is manuscript evid that austen continu t...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>52.87</td>\n",
       "      <td>11.24</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>there is manuscript evidence that austen conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[in, a, remarkable, comparative, analysis, man...</td>\n",
       "      <td>19</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>there is manuscript evid that austen continu t...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.27</td>\n",
       "      <td>14.55</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>in a remarkable comparative analysis mandaean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[before, persephone, was, released, to, hermes...</td>\n",
       "      <td>40</td>\n",
       "      <td>4.725000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>there is manuscript evid that austen continu t...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>47.80</td>\n",
       "      <td>11.15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>before persephone was released to hermes who h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cogeneration, plants, are, commonly, found, i...</td>\n",
       "      <td>32</td>\n",
       "      <td>6.281250</td>\n",
       "      <td>1.781250</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>there is manuscript evid that austen continu t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>14.60</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>cogeneration plants are commonly found in dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geneva, is, the, city, in, switzerland, after...</td>\n",
       "      <td>20</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>there is manuscript evid that austen continu t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>68.10</td>\n",
       "      <td>8.58</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>geneva is the city in switzerland after zürich...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label  \\\n",
       "0  There is manuscript evidence that Austen conti...      1   \n",
       "1  In a remarkable comparative analysis , Mandaea...      1   \n",
       "2  Before Persephone was released to Hermes , who...      1   \n",
       "3  Cogeneration plants are commonly found in dist...      1   \n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
       "\n",
       "                                        preprocessed  word_count  \\\n",
       "0  [there, is, manuscript, evidence, that, austen...          35   \n",
       "1  [in, a, remarkable, comparative, analysis, man...          19   \n",
       "2  [before, persephone, was, released, to, hermes...          40   \n",
       "3  [cogeneration, plants, are, commonly, found, i...          32   \n",
       "4  [geneva, is, the, city, in, switzerland, after...          20   \n",
       "\n",
       "   avg_word_count  syllable_count  uncommon  difficult_words  \\\n",
       "0        4.485714        1.371429        14                7   \n",
       "1        6.000000        1.789474        14                8   \n",
       "2        4.725000        1.400000        15                9   \n",
       "3        6.281250        1.781250        22               14   \n",
       "4        4.650000        1.350000         7                4   \n",
       "\n",
       "                                                stem  discourse  \\\n",
       "0  there is manuscript evid that austen continu t...          4   \n",
       "1  there is manuscript evid that austen continu t...          2   \n",
       "2  there is manuscript evid that austen continu t...          7   \n",
       "3  there is manuscript evid that austen continu t...          0   \n",
       "4  there is manuscript evid that austen continu t...          0   \n",
       "\n",
       "   cohesive_features  flesch   dale  mcalpine  nouns_adjs  \\\n",
       "0                  2   52.87  11.24      48.0    0.228571   \n",
       "1                  1   35.27  14.55      23.0    0.315789   \n",
       "2                  3   47.80  11.15      57.0    0.175000   \n",
       "3                  1   22.08  14.60      38.0    0.593750   \n",
       "4                  2   68.10   8.58      29.0    0.400000   \n",
       "\n",
       "                                          normalized  \n",
       "0  there is manuscript evidence that austen conti...  \n",
       "1  in a remarkable comparative analysis mandaean ...  \n",
       "2  before persephone was released to hermes who h...  \n",
       "3  cogeneration plants are commonly found in dist...  \n",
       "4  geneva is the city in switzerland after zürich...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_pickle(\"data/features.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8767802",
   "metadata": {},
   "source": [
    "### Split dataset into test, train and dev\n",
    "\n",
    "We have a large enough dataset that we can effectively split it into train, development, and test sets, using the standard ratio of 80%, 10%, 10% for each, respectively. We'll use `split` from `numpy` to split the data into train, dev, and test separately. We'll call these `train_df`, `dev_df`, and `test_df`. It's important to note that `split` does not shuffle, so we'll use `DataFrame.sample()` and randomly resample our entire dataset to get a random shuffle before the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d61f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3d9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a text column that holds our clean data set in a string format\n",
    "df['text'] = [' '.join(map(str, l)) for l in df['preprocessed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbb4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit # helps ensure that classes are balanced before testing\n",
    "X = df[['text']].values\n",
    "y = df[['label']].values\n",
    "\n",
    "s = StratifiedShuffleSplit(n_splits=1, test_size =0.2, random_state=42)  \n",
    "\n",
    "for train_index, test_index in s.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9363b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322886, 80722)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b857c4e",
   "metadata": {},
   "source": [
    "### Convert text data to features\n",
    "\n",
    "We'll be using a `TfIdfVectorizer` to convert the text into features.\n",
    "\n",
    "Tfidf is a numerical statistic that is meant to reflect how important a word is to a document in a corpus. The tf–idf score increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word. This helps to adjust for the words that appear more frequently in general. \n",
    "\n",
    "I hypothesize that using tf-idf rarer words which are often harder to comprehend will have higher weights than easier words that appear more frequently.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6103d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitialize our vectorizer\n",
    "vectorizer= TfidfVectorizer(max_features=10000,ngram_range=(1,2)) # set max vocab to 10000\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train.flatten())\n",
    "X_test_tfidf = vectorizer.transform(X_test.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e97fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of the vectors\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "302c79cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((322886, 10000), (80722, 10000))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of our data\n",
    "X_train_tfidf.shape, X_test_tfidf.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65b962",
   "metadata": {},
   "source": [
    "### Fit the classifier on a subset of the data\n",
    "\n",
    "Finally, let's fit the classifier. For a start we'll use `LogisticRegression`.To train our classifier, we first create a `LogisticRegression` object and call `fit` passing in `X_train` and `y_train`.\n",
    "\n",
    "For this cell, let's just use the first 10,000 rows of `X_train` and `y_train` to fit the classifier. \n",
    "\n",
    "In general, when we have a large dataset, it's useful to go end-to-end and train one of these half-baked classifiers to verify that your model works as expected. \n",
    "\n",
    "*Notes:*\n",
    "1. We use the `lbfgs` solver, as this generally Just Works™ and is fast.\n",
    "2. `X_train` is a numpy array, so you'll need to use array indexing operations to get the first 10,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9817824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(solver=\"lbfgs\",random_state=RANDOM_SEED)\n",
    "\n",
    "clf.fit(X_train_tfidf[:10000],np.array(y_train)[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55fd07",
   "metadata": {},
   "source": [
    "### Create Dummy classifiers\n",
    "\n",
    "It's always important to contextualize our results by comparing it with naive classifiers. If these classifiers do well, then your task is easy! If not, then you can see how much better your system does at first. We'll use two different strategies using the [Dummy Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) class. Create two `DummyClassifier` instances that use the `uniform` (guess randomly) and `most_frequent` strategies and fit these on the training data so we can compare them with our regressor that was trained on 10K instances. In general, you probably always want to at least compare with these two baselines in a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a65cb880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(constant=None, random_state=42, strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(constant=None, random_state=42, strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(constant=None, random_state=42, strategy='most_frequent')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "duni=DummyClassifier(strategy=\"uniform\",random_state=RANDOM_SEED)\n",
    "dmos=DummyClassifier(strategy=\"most_frequent\",random_state=RANDOM_SEED)\n",
    "\n",
    "duni.fit(X_train_tfidf[:10000],np.array(y_train)[:10000])\n",
    "dmos.fit(X_train_tfidf[:10000],np.array(y_train)[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37026441",
   "metadata": {},
   "source": [
    "### Let's generate our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acf85717",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dev_preds=clf.predict(X_test_tfidf)\n",
    "duni_dev_preds=duni.predict(X_test_tfidf)\n",
    "dmos_dev_preds=dmos.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b3c22",
   "metadata": {},
   "source": [
    "### Score our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab59e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1 = f1_score(y_test, clf_dev_preds)\n",
    "rand_f1 = f1_score(y_test, duni_dev_preds)\n",
    "mf_f1 = f1_score(y_test, dmos_dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "594bd7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666122943561542\n",
      "0.5066888608741417\n",
      "0.6765800475448808\n"
     ]
    }
   ],
   "source": [
    "print(lr_f1)\n",
    "print(rand_f1)\n",
    "print(mf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93428b",
   "metadata": {},
   "source": [
    "## Train on the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2270a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2=LogisticRegression(solver=\"lbfgs\",random_state=RANDOM_SEED)\n",
    "\n",
    "clf2.fit(X_train_tfidf,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7351ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2_test_preds=clf2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2714d53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071695940109416\n"
     ]
    }
   ],
   "source": [
    "clf2_f1 = f1_score(y_test, clf2_test_preds)\n",
    "print(clf2_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9ff4c",
   "metadata": {},
   "source": [
    "Let's try and remove stop words and see if that helps things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87cdb6",
   "metadata": {},
   "source": [
    "# Logistic regression with stop words removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "831a22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(df['text'], df['label'], \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58ff9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitialize our vectorizer\n",
    "vect= TfidfVectorizer(max_features=10000,stop_words='english',ngram_range=(1,2)) # set max vocab to 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34651464",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(df['text'])\n",
    "\n",
    "Train_X_Tfidf = vect.transform(X_train)\n",
    "Test_X_Tfidf = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47021737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3=LogisticRegression(solver=\"lbfgs\",random_state=RANDOM_SEED)\n",
    "\n",
    "clf3.fit(Train_X_Tfidf,np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f710466",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3_test_preds=clf3.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6df257c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071695940109416\n"
     ]
    }
   ],
   "source": [
    "clf3_f1 = f1_score(y_test, clf3_test_preds)\n",
    "print(clf2_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16aba52",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5d78a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6023636678972275, 0.6970000188796799)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap= True,\n",
    " max_depth=50,\n",
    " max_features='auto',\n",
    " min_samples_leaf=4,\n",
    " min_samples_split=10,\n",
    " n_estimators=800)\n",
    "\n",
    "rf.fit(Train_X_Tfidf,y_train)\n",
    "rf_preds = rf.predict(Test_X_Tfidf)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "rf_acc, rf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25308d0",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c442d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(C=0.5, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,y_train)\n",
    "\n",
    "pred_SVM = SVM.predict(Test_X_Tfidf)\n",
    "svm_acc = accuracy_score(y_test, pred_SVM)\n",
    "svm_f1 = f1_score(y_test, predictions_SVM)\n",
    "svm_acc, svm_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
